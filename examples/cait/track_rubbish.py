# Python code generated by CAIT's Visual Programming Interface

from sqlalchemy import true
import cait.essentials
import threading
import time


object_coordinate = None
screen_center = None
rotate_power = None
x1 = None
object_of_interest = None
x2 = None
object_center = None
coordinates = None
object2 = None
power = None
robot_inventor_hub = 'Robot Inventor: A8:E2:C1:95:22:45'
motor_scoop = 'motor_D'
motor_wheels = 'motor_B'
motor_camera = 'motor_F'
target_object_name = "rubbish"

preview_width = 640
preview_heigth = 360

nn_input_size=300

"""Describe this function...
"""
def follow_object(object_coordinate):
    #TODO: instead of moving the camera to follow object we need to move the wheels
    global screen_center, rotate_power, x1, object_of_interest, x2, object_center, coordinates, object2, power
    screen_center = 640 / 2
    x1 = object_coordinate[0]
    x2 = object_coordinate[2]
    
    object_center = x1 + (x2 - x1) / 2
    rotate_power = cait.essentials.update_pid((object_center - screen_center))['value']
    cait.essentials.set_motor_power(robot_inventor_hub, motor_wheels, rotate_power)
    return rotate_power
    
def scoop():
    # TODO: Implement function to lower and raise the scoop
    #hooked up to motor D
    # Lower scoop
    cait.essentials.control_motor(robot_inventor_hub, motor_scoop, 1, '3s')
    # wait - assuming target object falls in
    time.sleep(3)
    # Raise scoop
    cait.essentials.control_motor(robot_inventor_hub, motor_scoop, -1, '3s')
    
    return true
    
# Auto generated dispatch function code
def dispatch_func_0():
    global object2, coordinates, object_of_interest
    power = follow_object(object2)
# End of auto generated dispatch function


def setup():
    spatial_object_detection_config = [ #this one definitely works
        ["add_rgb_cam_node", 640, 360], 
        ["add_rgb_cam_preview_node"],
        ["add_stereo_cam_node", False], 
        ["add_stereo_frame_node"],
        ["add_spatial_mobilenetSSD_node", "object_detection", "ssdlite_mbv2_coco.blob", 300, 300, 0.5]
    ]

    face_detection_config = [
        ["add_rgb_cam_node", 640, 360], 
        ["add_rgb_cam_preview_node"],
        ["add_stereo_cam_node", False], 
        ["add_stereo_frame_node"],
        ["add_spatial_mobilenetSSD_node", "object_detection", "face-detection-retail-0004_openvino_2021.2_6shave.blob", 300, 300]]
    
    rubbish_detection_pipeline_config = [
        ["version", "2021.4"], # need to explicitly specify OpenVINO version
        ["add_rgb_cam_node", 640, 360], 
        ["add_rgb_cam_preview_node"],
        ["add_stereo_cam_node", False], 
        ["add_stereo_frame_node"],
        ["add_spatial_mobilenetSSD_node", "object_detection", "rubbish-detection_openvino_2021.4_5shave.blob", 300, 300, 0.5]
    ]

    # Using face detection model for now as it's easier to use for testing. Faces are more reliably recognised compared to other stuff
    vision_init_result = cait.essentials.initialize_component('vision', processor='oakd', mode=rubbish_detection_pipeline_config)
    if not vision_init_result[0]:
        print(vision_init_result[1])
    
    # comment out robot init if you want to just test the recognition
    #cait.essentials.initialize_component('control', [robot_inventor_hub])
    
    cait.essentials.initialize_pid(0.015, 0, 0)
    
def main():
    global object_coordinate, screen_center, rotate_power, x1, object_of_interest, x2, object_center, coordinates, object2, power
    while True:
        #TODO: error, nothing detected here, returns empty object
        object_of_interest = cait.essentials.detect_objects(processor='oakd', spatial=True)

        target_object_index=-1
        if object_of_interest is not None:
            if target_object_name in object_of_interest["names"]:
                target_object_index = object_of_interest["names"].index(target_object_name)
            # object_of_interest['names'] //grab first index of the target object class
            # object_of_interest['coordinates']
        
            cait.essentials.draw_detected_objects(object_of_interest)
            coordinates = object_of_interest['coordinates']

        #if len(coordinates) > 0:
        if target_object_index > -1:
            object2 = coordinates[target_object_index]
            # dispatch_thread_0 = threading.Thread(target=dispatch_func_0, daemon=True)
            # dispatch_thread_0.start()

if __name__ == "__main__":
    setup()
    main()